{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcript1 - [link](https://www.youtube.com/watch?v=BDIRabVP24o) (ENGLISH SPEECH | ELON MUSK: Think Big & Dream Even Bigger)\n",
    "\n",
    "Transcript2 - [link](https://www.englishspeecheschannel.com/english-speeches/elon-musk-speech/) (Elon Musk Speech: Future, A.I., and Mars)\n",
    "\n",
    "Transcript3 - [link](https://www.youtube.com/watch?v=IgKWPdJWuBQ&t=21s) (Элон Маск: Элон Маск: Человек, создавший Tesla, SpaceX, SolarCity...)\n",
    "\n",
    "Transcript4 - [link](https://www.youtube.com/watch?v=zIwLWfaAg-8) (Elon Musk: The future we're building -- and boring | TED)\n",
    "\n",
    "Transcript5 - [link](https://www.youtube.com/watch?v=H7Uyfqi_TE8) (Making Humans a Multiplanetary Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sentences(text):\n",
    "    new = ''\n",
    "    for i in range(len(text) - 1):\n",
    "        if text[i] == '.' and text[i + 1] == ' ':\n",
    "            new += '*'\n",
    "        else:\n",
    "            new += text[i]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform1():\n",
    "    f = open('Data/Data1.txt', 'r')\n",
    "    \n",
    "    text = f.read()\n",
    "    sentences = []\n",
    "    for sentence in text.split('.\\n'):\n",
    "        sentences.append(sentence.strip().replace('\\n', ' '))\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_podcast1(web):\n",
    "    \n",
    "    link = 'https://www.rev.com/blog/transcripts/joe-rogan-elon-musk-podcast-transcript-may-7-2020'\n",
    "    web.get(link)\n",
    "    \n",
    "    sleep(4)\n",
    "    \n",
    "    sentences = []\n",
    "    main = web.find_element_by_class_name('fl-callout-text')\n",
    "    for phrase in web.find_element_by_class_name('fl-callout-text').find_elements_by_css_selector('p'):\n",
    "        if len(phrase.text.split('\\n')) == 2:\n",
    "            name, text = phrase.text.split('\\n')\n",
    "        if 'Elon Musk:' in name:\n",
    "            for sent in text.split('.'):\n",
    "                sentences.append(sent)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_podcast2(web):\n",
    "    link = 'https://sonix.ai/resources/full-transcript-joe-rogan-experience-elon-musk/'\n",
    "    web.get(link)\n",
    "    \n",
    "    sleep(5)\n",
    "    \n",
    "    sentences = []\n",
    "    for x in web.find_elements_by_class_name('sonix--transcript-exchange'):\n",
    "        if len(x.text.split('\\n')) == 3:\n",
    "            _, name, phrase = x.text.split('\\n')\n",
    "            if name == 'Elon Musk':\n",
    "                for sent in phrase.split('.'):\n",
    "                    sentences.append(sent)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def parse():\n",
    "    script_dir = os.path.dirname(os.path.realpath('chromedriver'))\n",
    "    webdriver_path = os.path.join(script_dir, 'chromedriver')\n",
    "    web = webdriver.Chrome(webdriver_path)\n",
    "    \n",
    "    link = 'https://www.englishspeecheschannel.com/english-speeches/elon-musk-speech/'\n",
    "    web.get(link)\n",
    "    sleep(5)\n",
    "    \n",
    "    read_more = web.find_element_by_class_name('read-link')\n",
    "    read_more.click()\n",
    "    \n",
    "    part1 = []\n",
    "    header = web.find_element_by_css_selector('#qtcontents > div > div.col.s12.m12.l8 > div > div:nth-child(3) > div > div > div > div > div')\n",
    "    for block in header.find_elements_by_css_selector('p')[3:6]: ## part1\n",
    "        part1.append(block.text)\n",
    "\n",
    "    part2 = web.find_element_by_class_name('read_div').text.split('\\n') ## part2\n",
    "    text = part1 + part2\n",
    "\n",
    "    sentences = []\n",
    "    for block in text:\n",
    "        if (block[-1] == '?' and len(block.split('.')) < 10) or (len(block.split('.')) < 6):\n",
    "            continue\n",
    "\n",
    "        block = set_sentences(block)\n",
    "            \n",
    "        for sentence in block.split('*'):\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    sentences = list(filter(lambda x: ' – ' not in x, sentences))\n",
    "    \n",
    "    sentences1 = get_podcast1(web)\n",
    "    sentences2 = get_podcast2(web)\n",
    "    \n",
    "    return sentences + sentences1 + sentences2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2(filename):\n",
    "    f = open(filename, 'r')\n",
    "    text = f.read().replace('\\n\\n', ' ').replace('(Laughter)', '').replace('(Applause)', '')\n",
    "    f.close()\n",
    "\n",
    "    first = text.split('EM:')[0]\n",
    "    other = text.split('EM:')[1:]\n",
    "\n",
    "    blocks = []\n",
    "    blocks.append(first.split('Elon Musk:')[1].split('CA:')[0])\n",
    "\n",
    "    for block in other:\n",
    "        blocks.append(block.split('CA:')[0].replace('\\n', ''))\n",
    "\n",
    "\n",
    "    sentences = []\n",
    "    for block in blocks:\n",
    "        \n",
    "        block = set_sentences(block)\n",
    "        for sent in block.split('*'):\n",
    "            sentences.append(sent)\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform3():\n",
    "    f = open('Data/Data4.txt', 'r')\n",
    "\n",
    "    text = f.read().replace('\\n\\n', ' ').replace('(Laughter)', '').replace('[APPLAUSE]', '')\n",
    "    text = text.split('ELON MUSK:')[1]\n",
    "    text = set_sentences(text)\n",
    "    sentences = text.split('*')\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequent_words(speeches):\n",
    "    count_unique = {}\n",
    "    for sent in speeches:\n",
    "        for word in sent.split():\n",
    "            if word in count_unique:\n",
    "                count_unique[word] += 1\n",
    "            else:\n",
    "                count_unique[word] = 1\n",
    "\n",
    "\n",
    "    sorted_dict = {}\n",
    "    sorted_keys = sorted(count_unique, key=count_unique.get, reverse=True)\n",
    "\n",
    "    for w in sorted_keys:\n",
    "        sorted_dict[w] = count_unique[w]\n",
    "\n",
    "    stop_words = list(sorted_dict.keys())[:80]\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "def clear_sent(sent, stop_words):\n",
    "    split_str = sent.split()\n",
    "    filtered_str = list(filter(lambda s: s not in stop_words, split_str))\n",
    "\n",
    "    return filtered_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = []\n",
    "speeches += transform1()\n",
    "speeches += transform2('Data/Data2.txt')\n",
    "speeches += transform2('Data/Data3.txt')\n",
    "speeches += transform3()\n",
    "speeches += parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = find_frequent_words(speeches)\n",
    "speeches_cleared = list(filter(lambda x: len(clear_sent(x, stop_words)) > 6 and '--' not in x ,speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Speech': speeches_cleared})\n",
    "df['Speech'] = df['Speech'].apply(lambda x: x.replace('\\\\', ''))\n",
    "df.to_csv('Elon_phrases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So, I thought — I was trying to think what’s t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And I thought, perhaps tell the story of how I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I often find myself wondering, how did this ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the reason I thought that was because I re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you go back say, 300 years, the things we t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Speech\n",
       "0  So, I thought — I was trying to think what’s t...\n",
       "1  And I thought, perhaps tell the story of how I...\n",
       "2  I often find myself wondering, how did this ha...\n",
       "3  And the reason I thought that was because I re...\n",
       "4  If you go back say, 300 years, the things we t..."
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
